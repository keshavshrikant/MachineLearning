{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"competition","sourceId":67121,"databundleVersionId":7806901},{"sourceType":"modelInstanceVersion","sourceId":11371,"databundleVersionId":7771674,"modelInstanceId":5171}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-14T09:38:21.852607Z","iopub.execute_input":"2024-03-14T09:38:21.853162Z","iopub.status.idle":"2024-03-14T09:38:22.775172Z","shell.execute_reply.started":"2024-03-14T09:38:21.853132Z","shell.execute_reply":"2024-03-14T09:38:22.774106Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/llm-prompt-recovery/sample_submission.csv\n/kaggle/input/llm-prompt-recovery/train.csv\n/kaggle/input/llm-prompt-recovery/test.csv\n/kaggle/input/gemma/keras/gemma_2b_en/2/config.json\n/kaggle/input/gemma/keras/gemma_2b_en/2/tokenizer.json\n/kaggle/input/gemma/keras/gemma_2b_en/2/metadata.json\n/kaggle/input/gemma/keras/gemma_2b_en/2/model.weights.h5\n/kaggle/input/gemma/keras/gemma_2b_en/2/assets/tokenizer/vocabulary.spm\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/keshavshrikant/MachineLearning.git","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:38:29.158443Z","iopub.execute_input":"2024-03-14T09:38:29.158888Z","iopub.status.idle":"2024-03-14T09:38:31.167990Z","shell.execute_reply.started":"2024-03-14T09:38:29.158860Z","shell.execute_reply":"2024-03-14T09:38:31.166908Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'MachineLearning'...\nremote: Enumerating objects: 59, done.\u001b[K\nremote: Counting objects: 100% (59/59), done.\u001b[K\nremote: Compressing objects: 100% (42/42), done.\u001b[K\nremote: Total 59 (delta 20), reused 43 (delta 12), pack-reused 0\u001b[K\nUnpacking objects: 100% (59/59), 5.07 MiB | 9.31 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!cd MachineLearning && git checkout kaggle-gemma","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:38:31.170285Z","iopub.execute_input":"2024-03-14T09:38:31.170698Z","iopub.status.idle":"2024-03-14T09:38:32.159448Z","shell.execute_reply.started":"2024-03-14T09:38:31.170661Z","shell.execute_reply":"2024-03-14T09:38:32.158309Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Branch 'kaggle-gemma' set up to track remote branch 'kaggle-gemma' from 'origin'.\nSwitched to a new branch 'kaggle-gemma'\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\ntransformations = []\nwith open(\"MachineLearning/gpt_generated_tranformations.jsonl\", \"r\") as fin:\n    for line in fin:\n        instruction_info = json.loads(line)\n#         print(instruction_info)\n        transformations.append(instruction_info) \n\ntrans_df = pd.DataFrame.from_records(transformations)\ntrans_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:38:32.788893Z","iopub.execute_input":"2024-03-14T09:38:32.789621Z","iopub.status.idle":"2024-03-14T09:38:32.826118Z","shell.execute_reply.started":"2024-03-14T09:38:32.789587Z","shell.execute_reply":"2024-03-14T09:38:32.825184Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                         instruction  \\\n0  Start with a hypothetical outcome, exploring v...   \n1  Highlight a background detail that was previou...   \n2  Develop a list of potential spin-off stories f...   \n3  Write a letter from one character to another, ...   \n4  Develop a step-by-step guide on how to cultiva...   \n\n                                         actual_text  \\\n0  Hi Delta Airline,\\n\\nI am Ao Ni, I send this e...   \n1  Swimming in the ocean can be an exhilarating e...   \n2  Below is a recursive Python function fib(n) th...   \n3  * Planned fundraising efforts for the next wee...   \n4  Hi Landlord, I wanted to send this message to ...   \n\n                                      rewritten_text  \n0  In a parallel universe where my flight from La...  \n1  The sound of crashing waves against the shore ...  \n2  Within the world of the Fibonacci sequence, th...  \n3  Dear Sarah, I wanted to update you on the prog...  \n4  To cultivate a thriving indoor garden in a sma...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>actual_text</th>\n      <th>rewritten_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Start with a hypothetical outcome, exploring v...</td>\n      <td>Hi Delta Airline,\\n\\nI am Ao Ni, I send this e...</td>\n      <td>In a parallel universe where my flight from La...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Highlight a background detail that was previou...</td>\n      <td>Swimming in the ocean can be an exhilarating e...</td>\n      <td>The sound of crashing waves against the shore ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Develop a list of potential spin-off stories f...</td>\n      <td>Below is a recursive Python function fib(n) th...</td>\n      <td>Within the world of the Fibonacci sequence, th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Write a letter from one character to another, ...</td>\n      <td>* Planned fundraising efforts for the next wee...</td>\n      <td>Dear Sarah, I wanted to update you on the prog...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Develop a step-by-step guide on how to cultiva...</td>\n      <td>Hi Landlord, I wanted to send this message to ...</td>\n      <td>To cultivate a thriving indoor garden in a sma...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nos.environ[\"KAGGLE_USERNAME\"] = UserSecretsClient().get_secret('KAGGLE_USERNAME')\nos.environ[\"KAGGLE_KEY\"] = UserSecretsClient().get_secret('KAGGLE_KEY')","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:38:40.516644Z","iopub.execute_input":"2024-03-14T09:38:40.517225Z","iopub.status.idle":"2024-03-14T09:38:40.912424Z","shell.execute_reply.started":"2024-03-14T09:38:40.517195Z","shell.execute_reply":"2024-03-14T09:38:40.911450Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U keras-nlp\n!pip install -q -U keras>=3","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:38:42.359524Z","iopub.execute_input":"2024-03-14T09:38:42.359867Z","iopub.status.idle":"2024-03-14T09:39:13.135433Z","shell.execute_reply.started":"2024-03-14T09:38:42.359842Z","shell.execute_reply":"2024-03-14T09:39:13.132872Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n# Avoid memory fragmentation on JAX backend.\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:39:13.138744Z","iopub.execute_input":"2024-03-14T09:39:13.139372Z","iopub.status.idle":"2024-03-14T09:39:13.148445Z","shell.execute_reply.started":"2024-03-14T09:39:13.139321Z","shell.execute_reply":"2024-03-14T09:39:13.147277Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import keras\nimport keras_nlp","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:39:13.150095Z","iopub.execute_input":"2024-03-14T09:39:13.150434Z","iopub.status.idle":"2024-03-14T09:39:25.808222Z","shell.execute_reply.started":"2024-03-14T09:39:13.150404Z","shell.execute_reply":"2024-03-14T09:39:25.807435Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2024-03-14 09:39:16.685004: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-14 09:39:16.685110: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-14 09:39:16.822001: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:39:37.071566Z","iopub.execute_input":"2024-03-14T09:39:37.072204Z","iopub.status.idle":"2024-03-14T09:40:33.107833Z","shell.execute_reply.started":"2024-03-14T09:39:37.072172Z","shell.execute_reply":"2024-03-14T09:40:33.106962Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# template = \"\"\"Provided below is a creative writing paragraph and an instruction for rewriting it in a certain manner. Please follow the instruction to the tee and reqrite the paragraph as specified. \n\n# Paragraph:\n# {para}\n\n# Instruction:\n# {instruction}\n\n# Response: {response}\n# \"\"\"\n\n# prompt","metadata":{"execution":{"iopub.status.busy":"2024-03-14T07:11:54.523884Z","iopub.execute_input":"2024-03-14T07:11:54.524241Z","iopub.status.idle":"2024-03-14T07:11:54.532251Z","shell.execute_reply.started":"2024-03-14T07:11:54.524215Z","shell.execute_reply":"2024-03-14T07:11:54.531203Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"\"Provided below is a creative writing paragraph and an insturction for rewriting it in a certain manner. Please follow the insturction to the tee and reqrite the paragraph as specified. \\n\\nParagraph:\\nHi Delta Airline,\\n\\nI am Ao Ni, I send this email regarding a cancelled flight of mine and to request documents to claim my travel insurance. \\n\\nI just received an email from you that my flight from Las Vegas to New York today at 10 PM was canceled due to mechanical issues. Even though Delta Airline will refund me the cost of flight ticket, the last minute ticket for tomorrow's flight is extremely expensive, almost double the normal price. I have to get back to New York by tomorrow to attend a very important meeting so I have to pay for the ticket, plus one night stay at a hotel for tonight. \\n\\nWill you reimburse my hotel and ticket? If not, I will have to claim it through my travel insurance and I need two documents to support my case. First, the confirmation of my order. Second, I need a letter from you to state the reason of the cancellation and that Delta Airlines is not able to reimburse my loss. \\n\\nI understand that bad things happen sometimes but I am still annoyed by the last minute notice. You should have noticed me earlier so that I could have had more time to deal with it. \\n\\nPlease let me know if you need anything from me. You can reach me at 123-456-7890 or my email 123@gmail.com.\\n\\nInstruction:\\nStart with a hypothetical outcome, exploring various scenarios leading to that particular result.\\n\\nResponse: \\n\""},"metadata":{}}]},{"cell_type":"code","source":"prompt_recovery_template = \"\"\"Provided below is a creative writing paragraph and an interesting manner in which it has been rewritten. Your job is to figure out the insturction which would have been followed to rewrite the original paragraph in the interesting manner.  \n\nParagraph:\n{para}\n\nRewritten Paragraph:\n{rewritten}\n\nInstruction:\n{instruction}\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:34:26.420163Z","iopub.execute_input":"2024-03-14T09:34:26.420609Z","iopub.status.idle":"2024-03-14T09:34:26.426224Z","shell.execute_reply.started":"2024-03-14T09:34:26.420574Z","shell.execute_reply":"2024-03-14T09:34:26.425158Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df = []\n    \nfor index, row in trans_df.iterrows():\n\n    prompt = prompt_recovery_template.format(\n        para=row['actual_text'],\n        rewritten=row['rewritten_text'],\n        instruction=row['instruction'],\n    )\n\n    if len(prompt) < 850:\n        train_df.append(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:34:33.733871Z","iopub.execute_input":"2024-03-14T09:34:33.734285Z","iopub.status.idle":"2024-03-14T09:34:33.818984Z","shell.execute_reply.started":"2024-03-14T09:34:33.734254Z","shell.execute_reply":"2024-03-14T09:34:33.818185Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_df[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:34:36.052956Z","iopub.execute_input":"2024-03-14T09:34:36.053341Z","iopub.status.idle":"2024-03-14T09:34:36.059541Z","shell.execute_reply.started":"2024-03-14T09:34:36.053312Z","shell.execute_reply":"2024-03-14T09:34:36.058582Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'Provided below is a creative writing paragraph and an interesting manner in which it has been rewritten. Your job is to figure out the insturction which would have been followed to rewrite the original paragraph in the interesting manner.  \\n\\nParagraph:\\nAn unicorn, a white horse like animal with a horn in the forehead\\n\\nRewritten Paragraph:\\nMajestic horned steed, Pure white with magic allure, Unicorn in sight\\n\\nInstruction:\\nCraft a haiku summarizing the essence of the narrative in three lines.\\n'"},"metadata":{}}]},{"cell_type":"code","source":"gemma_lm.backbone.enable_lora(rank=4)\ngemma_lm.preprocessor.sequence_length = 850\n\noptimizer = keras.optimizers.AdamW(\n    learning_rate=5e-5,\n    weight_decay=0.01,\n    beta_1=0.9,\n    beta_2=0.999\n    )\n\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:34:53.865360Z","iopub.execute_input":"2024-03-14T09:34:53.865734Z","iopub.status.idle":"2024-03-14T09:34:54.352809Z","shell.execute_reply.started":"2024-03-14T09:34:53.865705Z","shell.execute_reply":"2024-03-14T09:34:54.352015Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"gemma_lm.fit(train_df, epochs=20, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T09:35:26.728642Z","iopub.execute_input":"2024-03-14T09:35:26.729003Z","iopub.status.idle":"2024-03-14T09:36:52.540571Z","shell.execute_reply.started":"2024-03-14T09:35:26.728973Z","shell.execute_reply":"2024-03-14T09:36:52.539157Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2024-03-14 09:36:50.405199: E external/xla/xla/pjrt/pjrt_stream_executor_client.cc:2732] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 5013541528 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:    9.35GiB\n              constant allocation:       532B\n        maybe_live_out allocation:    9.35GiB\n     preallocated temp allocation:    4.67GiB\n  preallocated temp fragmentation:     4.6KiB (0.00%)\n                 total allocation:   14.02GiB\n              total fragmentation:    76.9KiB (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 1.95GiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/transpose[permutation=(1, 0)]\" source_file=\"/tmp/ipykernel_34/1668031489.py\" source_line=1\n\t\tEntry Parameter Subshape: f32[256000,2048]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 830.08MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[1,850,256000]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 830.08MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]\" source_file=\"/tmp/ipykernel_34/1668031489.py\" source_line=1\n\t\tXLA Label: custom-call\n\t\tShape: f32[850,256000]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[16384,2048]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[16384,2048]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[16384,2048]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[16384,2048]\n\t\t==========================\n\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgemma_lm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_nlp/src/utils/pipeline_model.py:188\u001b[0m, in \u001b[0;36mPipelineModel.fit\u001b[0;34m(self, x, y, batch_size, sample_weight, validation_data, validation_split, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         (vx, vy, vsw) \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(\n\u001b[1;32m    182\u001b[0m             validation_data\n\u001b[1;32m    183\u001b[0m         )\n\u001b[1;32m    184\u001b[0m         validation_data \u001b[38;5;241m=\u001b[39m _convert_inputs_to_dataset(\n\u001b[1;32m    185\u001b[0m             vx, vy, vsw, batch_size\n\u001b[1;32m    186\u001b[0m         )\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:1159\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1157\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_token_bufs(result_token_bufs, sharded_runtime_token)\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxla_executable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sharded\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mneeds_check_special():\n\u001b[1;32m   1161\u001b[0m   out_arrays \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdisassemble_into_single_device_arrays()\n","\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 5013541528 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:    9.35GiB\n              constant allocation:       532B\n        maybe_live_out allocation:    9.35GiB\n     preallocated temp allocation:    4.67GiB\n  preallocated temp fragmentation:     4.6KiB (0.00%)\n                 total allocation:   14.02GiB\n              total fragmentation:    76.9KiB (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 1.95GiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/transpose[permutation=(1, 0)]\" source_file=\"/tmp/ipykernel_34/1668031489.py\" source_line=1\n\t\tEntry Parameter Subshape: f32[256000,2048]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 830.08MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[1,850,256000]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 830.08MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]\" source_file=\"/tmp/ipykernel_34/1668031489.py\" source_line=1\n\t\tXLA Label: custom-call\n\t\tShape: f32[850,256000]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[16384,2048]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[16384,2048]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[16384,2048]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[16384,2048]\n\t\t==========================\n\n"],"ename":"XlaRuntimeError","evalue":"RESOURCE_EXHAUSTED: Out of memory while trying to allocate 5013541528 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:    9.35GiB\n              constant allocation:       532B\n        maybe_live_out allocation:    9.35GiB\n     preallocated temp allocation:    4.67GiB\n  preallocated temp fragmentation:     4.6KiB (0.00%)\n                 total allocation:   14.02GiB\n              total fragmentation:    76.9KiB (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 1.95GiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/transpose[permutation=(1, 0)]\" source_file=\"/tmp/ipykernel_34/1668031489.py\" source_line=1\n\t\tEntry Parameter Subshape: f32[256000,2048]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 830.08MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[1,850,256000]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 830.08MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]\" source_file=\"/tmp/ipykernel_34/1668031489.py\" source_line=1\n\t\tXLA Label: custom-call\n\t\tShape: f32[850,256000]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[16384,2048]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[16384,2048]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[16384,2048]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[2048,16384]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 128.00MiB\n\t\tEntry Parameter Subshape: f32[16384,2048]\n\t\t==========================\n\n","output_type":"error"}]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/llm-prompt-recovery/test.csv')\n\nprompt = prompt_recovery_template.format(\n    para=test['original_text'].iloc[0],\n    rewritten=row['rewritten_text'].iloc[0],\n    instruction=\"\"\n)\n\nresponse = gemma_lm.generate(prompt,max_length=850)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response = response.replace(prompt,'')\nresponse","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\ngemma_lm.compile(sampler=sampler)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T07:12:25.836671Z","iopub.execute_input":"2024-03-14T07:12:25.837485Z","iopub.status.idle":"2024-03-14T07:12:25.846042Z","shell.execute_reply.started":"2024-03-14T07:12:25.837449Z","shell.execute_reply":"2024-03-14T07:12:25.845209Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}