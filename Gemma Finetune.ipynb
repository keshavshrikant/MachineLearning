{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":67121,"databundleVersionId":7806901,"sourceType":"competition"},{"sourceId":11371,"sourceType":"modelInstanceVersion","modelInstanceId":5171}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-14T11:31:27.926790Z","iopub.execute_input":"2024-03-14T11:31:27.927475Z","iopub.status.idle":"2024-03-14T11:31:28.298475Z","shell.execute_reply.started":"2024-03-14T11:31:27.927437Z","shell.execute_reply":"2024-03-14T11:31:28.297581Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/llm-prompt-recovery/sample_submission.csv\n/kaggle/input/llm-prompt-recovery/train.csv\n/kaggle/input/llm-prompt-recovery/test.csv\n/kaggle/input/gemma/keras/gemma_2b_en/2/config.json\n/kaggle/input/gemma/keras/gemma_2b_en/2/tokenizer.json\n/kaggle/input/gemma/keras/gemma_2b_en/2/metadata.json\n/kaggle/input/gemma/keras/gemma_2b_en/2/model.weights.h5\n/kaggle/input/gemma/keras/gemma_2b_en/2/assets/tokenizer/vocabulary.spm\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/keshavshrikant/MachineLearning.git","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:31:35.631750Z","iopub.execute_input":"2024-03-14T11:31:35.632556Z","iopub.status.idle":"2024-03-14T11:31:36.574047Z","shell.execute_reply.started":"2024-03-14T11:31:35.632523Z","shell.execute_reply":"2024-03-14T11:31:36.573059Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"fatal: destination path 'MachineLearning' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"!cd MachineLearning && git checkout kaggle-gemma","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\ntransformations = []\nwith open(\"MachineLearning/gpt_generated_tranformations.jsonl\", \"r\") as fin:\n    for line in fin:\n        instruction_info = json.loads(line)\n#         print(instruction_info)\n        transformations.append(instruction_info) \n\ntrans_df = pd.DataFrame.from_records(transformations)\ntrans_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:31:43.867117Z","iopub.execute_input":"2024-03-14T11:31:43.868031Z","iopub.status.idle":"2024-03-14T11:31:43.900277Z","shell.execute_reply.started":"2024-03-14T11:31:43.867982Z","shell.execute_reply":"2024-03-14T11:31:43.899410Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                         instruction  \\\n0  Start with a hypothetical outcome, exploring v...   \n1  Highlight a background detail that was previou...   \n2  Develop a list of potential spin-off stories f...   \n3  Write a letter from one character to another, ...   \n4  Develop a step-by-step guide on how to cultiva...   \n\n                                         actual_text  \\\n0  Hi Delta Airline,\\n\\nI am Ao Ni, I send this e...   \n1  Swimming in the ocean can be an exhilarating e...   \n2  Below is a recursive Python function fib(n) th...   \n3  * Planned fundraising efforts for the next wee...   \n4  Hi Landlord, I wanted to send this message to ...   \n\n                                      rewritten_text  \n0  In a parallel universe where my flight from La...  \n1  The sound of crashing waves against the shore ...  \n2  Within the world of the Fibonacci sequence, th...  \n3  Dear Sarah, I wanted to update you on the prog...  \n4  To cultivate a thriving indoor garden in a sma...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>actual_text</th>\n      <th>rewritten_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Start with a hypothetical outcome, exploring v...</td>\n      <td>Hi Delta Airline,\\n\\nI am Ao Ni, I send this e...</td>\n      <td>In a parallel universe where my flight from La...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Highlight a background detail that was previou...</td>\n      <td>Swimming in the ocean can be an exhilarating e...</td>\n      <td>The sound of crashing waves against the shore ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Develop a list of potential spin-off stories f...</td>\n      <td>Below is a recursive Python function fib(n) th...</td>\n      <td>Within the world of the Fibonacci sequence, th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Write a letter from one character to another, ...</td>\n      <td>* Planned fundraising efforts for the next wee...</td>\n      <td>Dear Sarah, I wanted to update you on the prog...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Develop a step-by-step guide on how to cultiva...</td>\n      <td>Hi Landlord, I wanted to send this message to ...</td>\n      <td>To cultivate a thriving indoor garden in a sma...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nos.environ[\"KAGGLE_USERNAME\"] = UserSecretsClient().get_secret('KAGGLE_USERNAME')\nos.environ[\"KAGGLE_KEY\"] = UserSecretsClient().get_secret('KAGGLE_KEY')","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:31:49.171780Z","iopub.execute_input":"2024-03-14T11:31:49.172598Z","iopub.status.idle":"2024-03-14T11:31:49.559308Z","shell.execute_reply.started":"2024-03-14T11:31:49.172559Z","shell.execute_reply":"2024-03-14T11:31:49.558270Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U keras-nlp\n!pip install -q -U keras>=3","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:31:52.751969Z","iopub.execute_input":"2024-03-14T11:31:52.752335Z","iopub.status.idle":"2024-03-14T11:32:20.090848Z","shell.execute_reply.started":"2024-03-14T11:31:52.752307Z","shell.execute_reply":"2024-03-14T11:32:20.089744Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n# Avoid memory fragmentation on JAX backend.\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:32:25.982258Z","iopub.execute_input":"2024-03-14T11:32:25.982650Z","iopub.status.idle":"2024-03-14T11:32:25.987808Z","shell.execute_reply.started":"2024-03-14T11:32:25.982610Z","shell.execute_reply":"2024-03-14T11:32:25.986814Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import keras\nimport keras_nlp","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:32:29.171897Z","iopub.execute_input":"2024-03-14T11:32:29.172299Z","iopub.status.idle":"2024-03-14T11:32:33.192063Z","shell.execute_reply.started":"2024-03-14T11:32:29.172266Z","shell.execute_reply":"2024-03-14T11:32:33.191288Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2024-03-14 11:32:30.357851: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-14 11:32:30.357901: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-14 11:32:30.359337: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:32:39.366747Z","iopub.execute_input":"2024-03-14T11:32:39.367406Z","iopub.status.idle":"2024-03-14T11:33:36.238857Z","shell.execute_reply.started":"2024-03-14T11:32:39.367371Z","shell.execute_reply":"2024-03-14T11:33:36.237968Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"prompt_recovery_template = \"\"\"Provided below is a creative writing paragraph and an interesting manner in which it has been rewritten. Your job is to figure out the insturction which would have been followed to rewrite the original paragraph in the interesting manner. Identify the style, tone, structure, point of view, theme, genre in which the original pragraph has been rewritten and then reconstruct the instruction.\n\nHere is an example:\nOriginal Text:\nThe competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.\n\nRewritten Text:\nHere is your shanty: (Verse 1) The text is rewritten, the LLM has spun, With prompts so clever, they've been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we'll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to be\n\nInstruction:\nConvert this into a sea shanty\n\nNow do it for this one!\n\nOriginal Text:\n{para}\n\nRewritten Text:\n{rewritten}\n\nInstruction:\n{instruction}\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:34:34.852549Z","iopub.execute_input":"2024-03-14T11:34:34.853514Z","iopub.status.idle":"2024-03-14T11:34:34.859201Z","shell.execute_reply.started":"2024-03-14T11:34:34.853477Z","shell.execute_reply":"2024-03-14T11:34:34.858299Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df = []\n    \nfor index, row in trans_df.iterrows():\n\n    prompt = prompt_recovery_template.format(\n        para=row['actual_text'],\n        rewritten=row['rewritten_text'],\n        instruction=row['instruction'],\n    )\n\n    if len(prompt) < 3000:\n        \n        train_df.append(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:34:41.778920Z","iopub.execute_input":"2024-03-14T11:34:41.779292Z","iopub.status.idle":"2024-03-14T11:34:41.856456Z","shell.execute_reply.started":"2024-03-14T11:34:41.779262Z","shell.execute_reply":"2024-03-14T11:34:41.855501Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"len(train_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:34:46.606472Z","iopub.execute_input":"2024-03-14T11:34:46.606853Z","iopub.status.idle":"2024-03-14T11:34:46.612968Z","shell.execute_reply.started":"2024-03-14T11:34:46.606821Z","shell.execute_reply":"2024-03-14T11:34:46.612085Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"506"},"metadata":{}}]},{"cell_type":"code","source":"gemma_lm.backbone.enable_lora(rank=4)\ngemma_lm.preprocessor.sequence_length = 3000\n\noptimizer = keras.optimizers.AdamW(\n    learning_rate=5e-5,\n    weight_decay=0.01,\n    beta_1=0.9,\n    beta_2=0.999\n    )\n\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:57:15.022253Z","iopub.execute_input":"2024-03-14T11:57:15.023024Z","iopub.status.idle":"2024-03-14T11:57:16.136601Z","shell.execute_reply.started":"2024-03-14T11:57:15.022966Z","shell.execute_reply":"2024-03-14T11:57:16.135244Z"},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgemma_lm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_lora\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m gemma_lm\u001b[38;5;241m.\u001b[39mpreprocessor\u001b[38;5;241m.\u001b[39msequence_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3000\u001b[39m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdamW(\n\u001b[1;32m      5\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m,\n\u001b[1;32m      6\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m      7\u001b[0m     beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m,\n\u001b[1;32m      8\u001b[0m     beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m\n\u001b[1;32m      9\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_nlp/src/models/backbone.py:176\u001b[0m, in \u001b[0;36mBackbone.enable_lora\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_lora\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    175\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_lora\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lora_enabled_layers\u001b[38;5;241m.\u001b[39mappend(i)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/einsum_dense.py:239\u001b[0m, in \u001b[0;36mEinsumDense.enable_lora\u001b[0;34m(self, rank, a_initializer, b_initializer)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot enable lora on a layer that isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yet built.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m     )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_enabled:\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlora is already enabled. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis can only be done once per layer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m     )\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracker\u001b[38;5;241m.\u001b[39mlocked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_kernel_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    246\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlora_kernel_a\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    247\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (rank,)),\n\u001b[1;32m    248\u001b[0m     initializer\u001b[38;5;241m=\u001b[39minitializers\u001b[38;5;241m.\u001b[39mget(a_initializer),\n\u001b[1;32m    249\u001b[0m     regularizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_regularizer,\n\u001b[1;32m    250\u001b[0m )\n","\u001b[0;31mValueError\u001b[0m: lora is already enabled. This can only be done once per layer."],"ename":"ValueError","evalue":"lora is already enabled. This can only be done once per layer.","output_type":"error"}]},{"cell_type":"code","source":"gemma_lm.fit(train_df, epochs=2, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:34:58.761777Z","iopub.execute_input":"2024-03-14T11:34:58.762677Z","iopub.status.idle":"2024-03-14T11:55:40.460002Z","shell.execute_reply.started":"2024-03-14T11:34:58.762639Z","shell.execute_reply":"2024-03-14T11:55:40.459180Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/2\n\u001b[1m506/506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 1s/step - loss: 1.2524 - sparse_categorical_accuracy: 0.5858\nEpoch 2/2\n\u001b[1m506/506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 1s/step - loss: 0.5488 - sparse_categorical_accuracy: 0.8112\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c0bbc6780d0>"},"metadata":{}}]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/llm-prompt-recovery/test.csv')\n\nprompt = prompt_recovery_template.format(\n    para=test_df['original_text'].iloc[0],\n    rewritten=test_df['rewritten_text'].iloc[0],\n    instruction=\"\"\n)\n\nresponse = gemma_lm.generate(prompt,max_length=3000)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:56:11.282087Z","iopub.execute_input":"2024-03-14T11:56:11.282775Z","iopub.status.idle":"2024-03-14T11:56:35.800436Z","shell.execute_reply.started":"2024-03-14T11:56:11.282743Z","shell.execute_reply":"2024-03-14T11:56:35.799539Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"response = response.replace(prompt,'')\nresponse","metadata":{"execution":{"iopub.status.busy":"2024-03-14T11:56:41.511859Z","iopub.execute_input":"2024-03-14T11:56:41.512597Z","iopub.status.idle":"2024-03-14T11:56:41.518553Z","shell.execute_reply.started":"2024-03-14T11:56:41.512560Z","shell.execute_reply":"2024-03-14T11:56:41.517598Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"\"Copy the text below:\\n\\nThe text above is a secret message. Can you decrypt it?\\n\\nThe answer to the above question is:\\nThe text is rewritten, the LLM has spun, With prompts so clever, they've been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we'll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to be\\n</code>\\n\\nThis is the original text.\\n\\nHere is your shanty:\\n\\nThe text is rewritten, the LLM has spun,\\n\\nWith prompts so clever,\\n\\nthey've been outrun.\\n\\nThe goal is to find, the prompt so bright,\\n\\nTo crack the code, and shine the light.\\n\\nOh, this is a code competition, my dear,\\n\\nWith text and prompts,\\n\\nwe'll compete.\\n\\nTwo thousand texts, a challenge grand,\\n\\nTo guess the prompts,\\n\\nhand over hand.(Verse 2) The original text,\\n\\na treasure lost,\\n\\nThe rewrite prompt,\\n\\na secret to be\\n\\nCopy the text below:\\n\\nThe text above is a secret message. Can you decrypt it?\\n\\nThe answer to the above question is:\""},"metadata":{}}]},{"cell_type":"code","source":"prompt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\ngemma_lm.compile(sampler=sampler)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}